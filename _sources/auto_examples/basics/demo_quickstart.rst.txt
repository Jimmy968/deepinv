
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/basics/demo_quickstart.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        New to DeepInverse? Get started with the basics with the
        :ref:`5 minute quickstart tutorial <sphx_glr_auto_examples_basics_demo_quickstart.py>`.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_basics_demo_quickstart.py:


5 minute quickstart tutorial
============================

Follow this example to get started with DeepInverse in under 5 minutes.

**Contents**

1. `Install <#install>`__
2. `Physics <#physics>`__
3. `Models <#models>`__
4. `Datasets <#datasets>`__
5. `What's next <#what-s-next>`__

.. GENERATED FROM PYTHON SOURCE LINES 18-29

1. Install
~~~~~~~~~~

First, install and import the latest stable release of `deepinv`:

.. code:: bash

   pip install deepinv

We then get the device (CPU in the case of this example).


.. GENERATED FROM PYTHON SOURCE LINES 29-35

.. code-block:: Python


    import deepinv as dinv
    import torch

    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"








.. GENERATED FROM PYTHON SOURCE LINES 36-39

2. Physics
~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 42-44

In DeepInverse, `x` are images:


.. GENERATED FROM PYTHON SOURCE LINES 44-47

.. code-block:: Python


    x = dinv.utils.load_example("butterfly.png", device=device)








.. GENERATED FROM PYTHON SOURCE LINES 48-49

Images are tensors of shape `B, C, ...` where `B` is batch size, `C` are channels and `...` are spatial dimensions:

.. GENERATED FROM PYTHON SOURCE LINES 49-52

.. code-block:: Python


    print(x.shape)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    torch.Size([1, 3, 256, 256])




.. GENERATED FROM PYTHON SOURCE LINES 53-56

:ref:`Imaging forward operators <physics_intro>` are called `physics` and simulate
measurements `y` from `x`.


.. GENERATED FROM PYTHON SOURCE LINES 56-62

.. code-block:: Python


    physics = dinv.physics.Inpainting(x.shape[1:], mask=0.3, device=device)

    y = physics(x)









.. GENERATED FROM PYTHON SOURCE LINES 63-69

DeepInverse implements
:ref:`many different types of physics <physics>` across various imaging modalities.
Physics also possess noise models such as Gaussian or Poisson noise.

.. hint::
    Do you get a matplotlib LaTeX error when plotting? Disable LaTeX using `dinv.utils.disable_tex()`

.. GENERATED FROM PYTHON SOURCE LINES 69-77

.. code-block:: Python


    physics.noise_model = dinv.physics.GaussianNoise(sigma=0.1)

    y = physics(x)

    dinv.utils.plot({"GT": x, "Noisy Inpainting \nMeasurement": y})





.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_001.png
   :alt: GT, Noisy Inpainting  Measurement
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 78-80

Many physics also take
:ref:`physics parameters <parameter-dependent-operators>` such as `mask`, `filter`, `sigma` etc.:

.. GENERATED FROM PYTHON SOURCE LINES 80-89

.. code-block:: Python


    # Blur with Gaussian filter parameter
    filter = dinv.physics.blur.gaussian_blur((5, 5))

    physics = dinv.physics.BlurFFT(x.shape[1:], filter=filter, device=device)

    # Simulate measurements
    y = physics(x)








.. GENERATED FROM PYTHON SOURCE LINES 90-92

You can easily use your own params by passing these into the `physics`,
or you can use a `generator` to :ref:`generate random params <physics_generators>`:

.. GENERATED FROM PYTHON SOURCE LINES 92-114

.. code-block:: Python


    # Blur kernel random generator
    physics_generator = dinv.physics.generator.MotionBlurGenerator(
        psf_size=(31, 31), num_channels=3, device=device
    )

    # Generate a dict of random params {"filter": ...}
    params = physics_generator.step()

    # Update physics during forward call
    y2 = physics(x, **params)

    dinv.utils.plot(
        {
            "GT": x,
            "Blurred...": y,
            "... with Gaussian kernel": filter,
            "Blurred ...": y2,
            "...with motion kernel": params["filter"],
        }
    )




.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_002.png
   :alt: GT, Blurred..., ... with Gaussian kernel, Blurred ..., ...with motion kernel
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 115-118

Physics are powerful objects and :ref:`have many methods <physics_intro>`, for example a
pseudo-inverse:


.. GENERATED FROM PYTHON SOURCE LINES 118-124

.. code-block:: Python


    # You can also update params like so
    physics.update(filter=filter.to(device))

    x_pinv = physics.A_dagger(y)








.. GENERATED FROM PYTHON SOURCE LINES 125-127

As it is well-known in the field of inverse problems, the pseudo-inverse can give good results
if the problem is noiseless, but it completely fails in the presence of noise - this is why we need reconstructors!

.. GENERATED FROM PYTHON SOURCE LINES 127-139

.. code-block:: Python


    physics.noise_model = dinv.physics.GaussianNoise(sigma=0.1)

    y = physics(x)

    x_pinv_noise = physics.A_dagger(y)

    dinv.utils.plot(
        {"Pseudoinv \nw/o noise": x_pinv, "Pseudoinv \nwith noise": x_pinv_noise}
    )





.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_003.png
   :alt: Pseudoinv  w/o noise, Pseudoinv  with noise
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 140-144

.. tip::

   Want to use DeepInverse with your own physics operator? Check out :ref:`sphx_glr_auto_examples_basics_demo_custom_physics.py` for a tutorial!


.. GENERATED FROM PYTHON SOURCE LINES 147-157

3. Models
~~~~~~~~~

In DeepInverse, a `model` is a reconstruction algorithm that
**reconstructs** images from `y` and knowledge of `physics`.

.. tip::
    Many models, such as :class:`Reconstruct Anything Model <deepinv.models.RAM>`, are :ref:`pretrained reconstructors <pretrained-models>` and can
    be used out of the box. See :ref:`sphx_glr_auto_examples_basics_demo_pretrained_model.py` for a full example.


.. GENERATED FROM PYTHON SOURCE LINES 157-162

.. code-block:: Python


    model = dinv.models.RAM(pretrained=True, device=device)

    x_hat = model(y, physics)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/mterris/ram/resolve/main/ram.pth.tar" to /home/runner/.cache/torch/hub/checkpoints/ram.pth.tar
      0%|          | 0.00/136M [00:00<?, ?B/s]      6%|â–Œ         | 8.25M/136M [00:00<00:01, 86.0MB/s]     12%|â–ˆâ–        | 16.5M/136M [00:00<00:01, 84.3MB/s]     18%|â–ˆâ–Š        | 24.9M/136M [00:00<00:01, 85.4MB/s]     24%|â–ˆâ–ˆâ–       | 33.1M/136M [00:00<00:01, 80.8MB/s]     30%|â–ˆâ–ˆâ–ˆ       | 41.4M/136M [00:00<00:01, 82.7MB/s]     36%|â–ˆâ–ˆâ–ˆâ–‹      | 49.6M/136M [00:00<00:01, 83.8MB/s]     42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57.8M/136M [00:00<00:01, 82.1MB/s]     49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 66.5M/136M [00:00<00:00, 85.0MB/s]     55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 74.9M/136M [00:00<00:00, 85.8MB/s]     61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 83.1M/136M [00:01<00:00, 85.9MB/s]     67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 91.4M/136M [00:01<00:00, 83.7MB/s]     73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 99.9M/136M [00:01<00:00, 85.0MB/s]     79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 108M/136M [00:01<00:00, 83.4MB/s]      86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 117M/136M [00:01<00:00, 85.5MB/s]     92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 125M/136M [00:01<00:00, 86.5MB/s]     98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 134M/136M [00:01<00:00, 85.3MB/s]    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 136M/136M [00:01<00:00, 84.5MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 163-166

Plot the image `x`, the measurement `y` and the reconstructed image
`x_hat` and compute :ref:`metrics <metric>`:


.. GENERATED FROM PYTHON SOURCE LINES 166-181

.. code-block:: Python


    metric = dinv.metric.PSNR()

    psnr_y = metric(y, x).item()
    psnr_x_hat = metric(x_hat, x).item()

    dinv.utils.plot(
        {
            "Ground Truth": x,
            "Measurement": y,
            "Reconstruction": x_hat,
        },
        subtitles=["PSNR:", f"{psnr_y:.2f} dB", f"{psnr_x_hat:.2f} dB"],
    )




.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_004.png
   :alt: Ground Truth, Measurement, Reconstruction
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 182-186

Some models are only :ref:`denoisers <denoisers>` that **denoise**
images from `y` and `sigma`, which can be used to build many
:ref:`model-based reconstruction algorithms <iterative>`.


.. GENERATED FROM PYTHON SOURCE LINES 186-210

.. code-block:: Python


    denoiser = dinv.models.DRUNet(device=device)

    x_denoised = denoiser(y, sigma=0.1)

    model = dinv.optim.DPIR(sigma=0.1, denoiser=denoiser, device=device)

    x_hat = model(y, physics)

    dinv.utils.plot(
        {
            "Ground Truth": x,
            "Measurement": y,
            "Denoised": x_denoised,
            "Reconstruction": x_hat,
        },
        subtitles=[
            "PSNR:",
            f"{dinv.metric.PSNR()(y, x).item():.2f} dB",
            f"{dinv.metric.PSNR()(x_denoised, x).item():.2f} dB",
            f"{dinv.metric.PSNR()(x_hat, x).item():.2f} dB",
        ],
    )




.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_005.png
   :alt: Ground Truth, Measurement, Denoised, Reconstruction
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/drunet/resolve/main/drunet_deepinv_color_finetune_22k.pth?download=true" to /home/runner/.cache/torch/hub/checkpoints/drunet_deepinv_color_finetune_22k.pth
      0%|          | 0.00/125M [00:00<?, ?B/s]      7%|â–‹         | 8.25M/125M [00:00<00:01, 85.8MB/s]     13%|â–ˆâ–Ž        | 16.6M/125M [00:00<00:01, 86.9MB/s]     20%|â–ˆâ–ˆ        | 25.2M/125M [00:00<00:01, 88.2MB/s]     27%|â–ˆâ–ˆâ–‹       | 33.8M/125M [00:00<00:01, 87.3MB/s]     34%|â–ˆâ–ˆâ–ˆâ–      | 42.1M/125M [00:00<00:00, 86.9MB/s]     41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50.5M/125M [00:00<00:00, 85.9MB/s]     47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58.8M/125M [00:00<00:00, 84.2MB/s]     54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 66.9M/125M [00:00<00:00, 82.5MB/s]     60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75.1M/125M [00:00<00:00, 83.7MB/s]     67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83.1M/125M [00:01<00:00, 82.7MB/s]     73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 91.5M/125M [00:01<00:00, 84.1MB/s]     80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99.6M/125M [00:01<00:00, 83.3MB/s]     87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108M/125M [00:01<00:00, 84.0MB/s]      93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 116M/125M [00:01<00:00, 81.3MB/s]     99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124M/125M [00:01<00:00, 77.4MB/s]    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125M/125M [00:01<00:00, 82.2MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 211-216

DeepInverse covers
:ref:`many frameworks of reconstruction algorithms <reconstructors>`
including :ref:`deep model architectures <deep-reconstructors>`, :ref:`iterative algorithms <iterative>`, :ref:`sampling algorithms <sampling>`
(e.g. diffusion models), and :ref:`unfolded models <unfolded>`.


.. GENERATED FROM PYTHON SOURCE LINES 216-220

.. code-block:: Python


    # Reconstruct Anything Model foundation model
    model = dinv.models.RAM(pretrained=True, device=device)








.. GENERATED FROM PYTHON SOURCE LINES 221-225

.. tip::

   Want to use DeepInverse with your own network? Just inherit from the reconstructor base class :class:`deepinv.models.Reconstructor`!


.. GENERATED FROM PYTHON SOURCE LINES 228-239

4. Datasets
~~~~~~~~~~~

You can use DeepInverse with :ref:`dataset <datasets>`, for testing or training. First,
define a ground-truth dataset. We implement wrappers for
:ref:`many popular imaging datasets <datasets>` across domains including natural images,
medical imaging, satellite imaging, etc.

.. tip::
    It's easy to use your own dataset with DeepInverse. See :ref:`sphx_glr_auto_examples_basics_demo_custom_dataset.py` for a tutorial.


.. GENERATED FROM PYTHON SOURCE LINES 239-245

.. code-block:: Python


    dataset = dinv.datasets.SimpleFastMRISliceDataset(
        "data", anatomy="brain", download=True
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/820534 [00:00<?, ?it/s]    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 801k/801k [00:00<00:00, 32.5MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 246-250

:ref:`Datasets <datasets>` return either `x`, tuples `x, y` or `x, y, params` of images,
measurements, and optional physics parameters. Given a ground-truth
dataset, you can simulate a dataset with random physics:


.. GENERATED FROM PYTHON SOURCE LINES 250-268

.. code-block:: Python


    physics = dinv.physics.MRI(device=device)

    physics_generator = dinv.physics.generator.RandomMaskGenerator(
        (320, 320), device=device
    )

    path = dinv.datasets.generate_dataset(
        dataset,
        physics,
        save_dir="data",
        physics_generator=physics_generator,
        device=device,
    )

    dataset = dinv.datasets.HDF5Dataset(path, load_physics_generator_params=True)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Dataset has been saved at data/dinv_dataset0.h5




.. GENERATED FROM PYTHON SOURCE LINES 269-271

You can use this dataset to :ref:`test or train <trainer>` a model:


.. GENERATED FROM PYTHON SOURCE LINES 271-283

.. code-block:: Python


    import torch

    dinv.test(
        model,
        torch.utils.data.DataLoader(dataset),
        physics,
        plot_images=True,
        device=device,
    )





.. image-sg:: /auto_examples/basics/images/sphx_glr_demo_quickstart_006.png
   :alt: Ground truth, Measurement, No learning, Reconstruction
   :srcset: /auto_examples/basics/images/sphx_glr_demo_quickstart_006.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|                                                                                                                           | 0/2 [00:00<?, ?it/s]    Test:   0%|                                                                                                                     | 0/2 [00:00<?, ?it/s]    Test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 1/2 [00:04<00:04,  4.33s/it]    Test:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                      | 1/2 [00:04<00:04,  4.33s/it]    Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.34s/it]    Test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.34s/it]
    Test results:
    PSNR no learning: 30.459 +- 0.940
    PSNR: 40.170 +- 1.241

    {'PSNR no learning': 30.458813667297363, 'PSNR no learning_std': 0.9398998244909388, 'PSNR': 40.16980743408203, 'PSNR_std': 1.2413414594398378}



.. GENERATED FROM PYTHON SOURCE LINES 284-288

.. tip::

   Want to use DeepInverse with your own dataset? Check out :ref:`sphx_glr_auto_examples_basics_demo_custom_dataset.py` for a tutorial!


.. GENERATED FROM PYTHON SOURCE LINES 291-309

ðŸŽ‰ Well done, you now know how to use DeepInverse!

What's next?
~~~~~~~~~~~~

-  Try more basic examples, including
   :ref:`how to inference a pretrained model <sphx_glr_auto_examples_basics_demo_pretrained_model.py>`,
   :ref:`how to use your own dataset <sphx_glr_auto_examples_basics_demo_custom_dataset.py>`, or
   :ref:`how to use your custom physics operator <sphx_glr_auto_examples_basics_demo_custom_physics.py>`.
-  Dive deeper into our full library of examples.
-  Read the :ref:`User Guide <user_guide>` for further details on the
   concepts introduced here.
-  Want help?
   `Open an issue <https://github.com/deepinv/deepinv/issues>`_ ask
   a message on our `Discord <https://discord.gg/qBqY5jKw3p>`_ or
   get in touch with our
   `MAINTAINERS <https://github.com/deepinv/deepinv/blob/main/MAINTAINERS.md>`_.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 33.836 seconds)


.. _sphx_glr_download_auto_examples_basics_demo_quickstart.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_quickstart.ipynb <demo_quickstart.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_quickstart.py <demo_quickstart.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_quickstart.zip <demo_quickstart.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
